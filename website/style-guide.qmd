---
title: "Post45 Data Collective Tabular Data Style Guide"
description: "*Created by Em Nordling, August 2025; Updated December 2025*"
format:
  html:
    toc: true
    toc-location: right-body   # or left-body
    toc-title: "Table of Contents"
    toc-depth: 3
  

---



# <font color="midnightblue">**Introduction**</font>{#introduction}

In the **Post45 Data Collective Tabular Data Style Guide**, you will find what it says on the tin: a cheatsheet for how to present and submit your tabular data to P45DC. This guide provides support at multiple points throughout your data journey, whether you are actively making data decisions or have already collected, curated, and documented your data. Though our guidelines are targeted to the latter-end of the dataset lifecycle (specifically storage, publication, and reusability), they will also be helpful for making critical decisions well in advance of submitting to P45DC.

Every dataset is different and will require different decision-making processes. If you are working with data compiled by an external source, for instance, rather than compiling it independently, you might choose to keep the data as-is without standardizing entries per our suggestions in [Data Types](#data-types). Your dataset will not necessarily be rejected for not meeting every recommendation, nor do you need to make every appropriate change before submitting. Our editorial team will work with you to determine what changes are necessary long-term. However, we strongly encourage you to read this style guide well in advance of submission and to use it to guide your decisions. 

Is your dataset not tabular (e.g. TEI, visual)? Please reach out to our editorial team before submitting to discuss format and style recommendations.

At the Post45 Data Collective, we aim to make humanities research data accessible, usable, and responsible to its affiliated communities. Our style guide therefore looks to the [FAIR](https://www.go-fair.org/fair-principles/){.external target="_blank"} (Findability, Accessibility, Interoperability, Reuse) and [CARE](https://www.gida-global.org/care){.external target="_blank"} (Collective Benefit, Authority to Control, Responsibility, Ethics) Principles for data management and governance to guide our recommendations.



::: {.callout-note appearance="default"}
## Selected Resources

**Getting Started**

* [Humanities Data](https://cdh.princeton.edu/programs/humanities-data-new/){.external target="_blank"} (CDH@Princeton) 
* [The Data-Sitters Club](https://datasittersclub.github.io/site/index.html){.external target="_blank"} 
* [Visualizing Objects, Places, and Spaces: A Digital Project Handbook](https://handbook.pubpub.org/){.external target="_blank"} 
* [Data Literacies Workshop](https://app.dhrift.org/dynamic?user=dhri-curriculum&repo=workshops&file=data-literacies&instUser=dhri-curriculum&instRepo=dhrift-site-template){.external target="_blank"} (DHRI) 
* [Preserving Your Research Data](https://programminghistorian.org/en/lessons/preserving-your-research-data){.external target="_blank"} (Programming Historian)  

**Tips & Guidelines**

* [Data Curation Network‚Äôs Checklists for Data Curation](https://github.com/DataCurationNetwork/data-curation-checklists/){.external target="_blank"} 
* [NEH Data Management Plans](https://www.neh.gov/sites/default/files/inline-files/Data%20Management%20Plans%2C%202019.pdf){.external target="_blank"} 
* [CLARIN (Common Language Resources and Technology Infrastructure) Tools & Resources](https://www.clarin.eu/content/find-use-process){.external target="_blank"} 
* [Digital Curation Centre (DCC) Glossary](https://www.dcc.ac.uk/about/digital-curation/glossary){.external target="_blank"} 
* [Top 10 FAIR Data & Software Things](https://librarycarpentry.github.io/Top-10-FAIR/){.external target="_blank"} 
* [The Data Nutrition Project](https://datanutrition.org/){.external target="_blank"} 

**Data Cleaning & Curation Tools**

* [OpenRefine](https://openrefine.org/){.external target="_blank"} 
  * [‚ÄúCleaning Data with Open Refine"](https://programminghistorian.org/en/lessons/cleaning-data-with-openrefine){.external target="_blank"} 
  * [Post45DC OpenRefine Reconciliation Service](https://github.com/Post45-Data-Collective/openrefine-reconciliation-service){.external target="_blank"} 
* [Breve](https://hdlab.stanford.edu/breve/){.external target="_blank"} 
* [Tidyr](https://tidyr.tidyverse.org/articles/tidy-data.html){.external target="_blank"} (tidyverse suite of tools for R) 
* [Visidata](https://www.visidata.org/){.external target="_blank"} 
* [WTFcsv](https://www.databasic.io/wtfcsv){.external target="_blank"} 
* [Tidy data for Librarians](https://librarycarpentry.github.io/lc-spreadsheets/){.external target="_blank"}
* [DCN Data Curation Primers](https://datacuration.network/outputs/data-curation-primers/){.external target="_blank"} 

**Data Management Criticism**

* [Critical Dataset Studies Reading List](https://knowingmachines.org/reading-list){.external target="_blank"} 
* [Black Living Data Booklet](https://fjday.com/projects){.external target="_blank"}  
* [Against Cleaning](https://dhdebates.gc.cuny.edu/read/untitled-f2acf72c-a469-49d8-be35-67f9ac1e3a60/section/07154de9-4903-428e-9c61-7a92a6f22e51){.external target="_blank"}
:::

---

# <font color="midnightblue">**General Tips & Suggestions** </font>{#general-tips-suggestions}

We recommend the following basic best practices for preparing your dataset.

## 1. Consider Digital Legibility{#consider-digital-legibility}

Clean your data not just for human readability, but for digital legibility. 

* Check for unintentional **duplicate entries**, such as the same author name with slight variations in spelling. To do so, you might use the [‚ÄúCluster‚Äù function](https://openrefine.org/docs/manual/cellediting#cluster-and-edit){.external target="_blank"} in OpenRefine, or a programming approach where you display unique values or value counts.

* Remove **unnecessary punctuation or trailing white space**. Again, this is a task you could complete in OpenRefine (see [‚ÄúCommon Transforms‚Äù](https://openrefine.org/docs/manual/cellediting#transform){.external target="_blank"}) or with a [programming language](https://www.geeksforgeeks.org/python/python-remove-spaces-from-a-string/){.external target="_blank"}.

* Keep each field as distinct as possible. Ideally, each cell should only contain a **single value** (though there are exceptions).

## 2. Consider Use Cases{#consider-use-cases}

*How* do you envision future researchers using your dataset?

If they will use it to generate **data visualizations**‚Ä¶

* Prioritize **sortability**  
  * For example, using ISO 8601 for dates (1794-07-27) allows computers to easily sort them numerically, as compared to other variations (July 27, 1794; 7/27/1294; 27 July ‚Äò94) (See [Data Types](#data-types))
* Prioritize **consistency and standardization**  
  * For example, data compiled and curated by an external source might include variations in name spelling, formatting, etc. To enable easier and more accurate computational analysis, you will need to standardize the data drawn from these sources (see [Data Types](#data-types)).

If they will access it for **archival purposes**‚Ä¶

* Prioritize **comprehensiveness**  
  * For example, if researchers will use your dataset as a [finding aid](https://www.loc.gov/librarians/archival-description/){.external target="_blank"} to locate a particular text, you‚Äôll want to include as much identifying information as possible in easily skimmable fields  
* Prioritize **institutional or item-level accuracy**  
  * For example, a digitized newspaper might spell a person‚Äôs name differently than the ‚Äúofficial‚Äù records provided by external authorities like [Library of Congress](https://authorities.loc.gov/webvoy.htm){.external target="_blank"}. Rather than standardizing this data per our suggestions in [Data Types](#data-types), you may opt to retain the variations for the sake of historical accuracy OR include both versions in separate columns. 

*Who* do you envision accessing your dataset in the future?

Be attentive to **licensing requirements** that might vary based on the accessibility of your dataset.  

* For example, if you envision your dataset being free use, make sure to include a [non-commercial CC license](https://creativecommons.org/licenses/by-nc/4.0/){.external target="_blank"} with your data.  
* Check out the [Creative Commons Licensing quiz](https://creativecommons.org/chooser/){.external target="_blank"} to determine your licensing needs, as needed.

## 3. Use Appropriate Software{#use-appropriate-software}

   CSV files can theoretically be viewed and edited in many different programs and softwares; however, not all of them will enforce appropriate formatting upon export (see [Character Encoding](#character-encoding)). Avoid working with your data in text editors like Word, and instead stick to **programs designed for data work** specifically, like Excel , Google Sheets, R and RStudio, or Python and libraries like Pandas.

::: {.callout-note appearance="default"} 
## **What is a CSV File?** 

**CSV** (Comma-Separated Values) is a non-proprietary format, meaning that you do not need a special piece of software to open it (see [File Formats](#file-formats)). Rather than saving as a structured spreadsheet, CSV files are plain text files wherein each value is separated by a comma.  Learn more about CSV [here](https://www.geeksforgeeks.org/data-analysis/csv-file-format/){.external target="_blank"}. 
::: 

## 4. Consider Institutional Policies{#consider-institutional-policies}

   Are you producing your dataset through a grant funded by an organization like the NEH, Mellon Foundation, or your home university? Don‚Äôt forget to follow any of their **required dataset guidelines or data management plans** (e.g. NEH [guide](https://www.neh.gov/publicaccess){.external target="_blank"}), including requirements laid out by IRB, as applicable (e.g. [Emory IRB policies](https://irb.emory.edu/){.external target="_blank"}).

## 5. Document Decision-Making{#document-decision-making}

   **Document every step** of your decision-making process, from the micro (standardizing date formats) to the macro (your approach to determining an author‚Äôs gender). In addition to making your research more reproducible, transparent, and reflexive, you will also need this information to draft your [data essay](https://data.post45.org/submissions.html){.external target="_blank"} for P45DC.

---

# <font color="midnightblue">**Files & File Organization**</font>{#files-file-organization}

## File Formats{#file-formats}

Ensure that your data files are formatted for **sustainable, non-proprietary use**. What does it mean for a file format to be sustainable and non-proprietary? Well, a popular file format for working with spreadsheets is the Excel default that ends with the extension .xlsx. This is the default format when saving data in Excel. While .xlsx files can be very useful, they‚Äôre technically proprietary and owned by Microsoft, meaning that we can‚Äôt rely on them to be accessible forever outside of Microsoft‚Äôs ecosystem.

By contrast, a non-proprietary format for spreadsheet files is .csv, which stands for comma separated values. You can open a .csv file with virtually any software package or tool, and they have a better chance of being accessible in the future. You can easily save your spreadsheet in this format, even if using Excel, by clicking ‚ÄúSave as‚Ä¶,‚Äù browsing the ‚ÄúFile Format‚Äù drop-down, and selecting ‚ÄúCSV UTF-8.‚Äù One of the only drawbacks here is that you will lose any bells-and-whistles added with Excel, like colors added to cells or special filters.  

| Data Type | Proprietary Formats | Non-Proprietary Formats |
| :---- | :---- | :---- |
| **Tabular Data** | xls & xlsx (Excel) sxc, ods (OpenOffice) | csv |
| **Text Data** | docx, doc (Microsoft) gdoc (Google) |  txt, xml, html |
| **Databases** | mat (MatLab) gdb (ArcGIS) | csv, xml |
| **Images** | psd, psb, acv (Adobe) swf (Macromedia Flash) | tiff, png, jpg |
| **Audio** | wma, wmv (Windows) mov (QuickTime) | mp3, wav, flac |

> **Example**: *A small selection of proprietary file formats and their non-proprietary counterparts*

::: {.callout-note appearance="default"}
## **Quick Note** 

The data tables hosted by the Post45 Data Collective provide options to download datasets as a CSV, Excel file, or JSON file. We provide these options for convenience and because we know some users prefer Excel files. We are able to create these three derivative file formats‚ÄîCSV, Excel, JSON‚Äîfrom a single CSV file, so prospective authors can simply submit a CSV file when ready (if submitting tabular data).  If your dataset is not tabular (e.g. TEI, visual), please reach out to our editors before submitting to discuss format, organization, and naming recommendations. The [Data Curation Network](https://datacuration.network/outputs/data-curation-primers/){.external target="_blank"} provides additional information about file formats.
:::

## Representing Multiple Values{#representing-multiple-values}

Ideally, each cell of your CSV file should only contain a single value. However, if you are including multiple data points in one cell (e.g. a list of names), make sure to use a unique delimiter (not a comma) between each datapoint to ensure future users can split columns easily as needed. We recommend **semi-colons (;)** or **pipes (|).** 

For example, if you format your name fields as ‚ÄúLast Name, First Name‚Äù and include multiple entries in the same cell, you will have the following results when using software like Open Refine or Excel to split a column into multiple columns for analysis. 

| Internal Delimiter | Original Entry | Split Entries |
| :---- | :---- | :---- |
| **Comma-separated** | ‚ÄúDu Bois, W.E.B., Mayhew, Henry‚Äù | ‚ÄúDu Bois‚Äù‚ÄùW.E.B.‚Äù‚ÄùMayhew‚Äù‚ÄùHenry‚Äù |
| **Semicolon-separated** | ‚ÄúDu Bois, W.E.B.; Mayhew, Henry‚Äù | ‚ÄúDu Bois, W.E.B.‚Äù‚ÄùMayhew, Henry‚Äù |

> **Example**: *this is what split columns may look like if you use comma or semicolon-separated internal delimiters*

## Character Encoding{#character-encoding}

Have you ever opened up a spreadsheet and noticed that letters with accent marks or other diacritics are‚Ä¶ all messed up?

| Correct Character Encoding | Incorrect Character Encoding |
| :---- | :---- |
| Louise Gl√ºck | Louise Gl√É¬ºck |
| Louise Gl√ºck | Louise GlÔøΩck |

> **Example**: *this is what character encoding errors might look like* 

This is a common ‚Äúcharacter encoding‚Äù issue. Character encoding refers to systems that enable computers to represent, you guessed it, characters: individual letters like ‚Äúa‚Äù and ‚Äú√°‚Äù; emojis like üí©and ü¶≠; or symbols like ¬°, ¬£, and ‚Ç¨. We used to rely on many different encoding systems, but today **UTF-8 (Unicode Transformation Format)** is the most widely used. It can represent almost any character in most of the world‚Äôs languages.

When compiling or working with data, it‚Äôs important to save your data in a UTF-8 format and to ensure that diacritics and other special characters are preserved.

::: {.callout-note appearance="default"}
## **Important Note**

It‚Äôs very easy for character encodings to get messed up, especially when using Excel. For example, even if a file is correctly saved in a UTF-8 format, if you open it in Excel, the file often will *not* open as UTF-8 by default. So even if you or someone else correctly preserved special characters upon an initial ‚Äúsave,‚Äù if you re-open that file in Excel, the special characters may look garbled, and you may accidentally overwrite the data in this garbled format.

This is a known and notorious problem. Microsoft has [offered two suggestions](https://support.microsoft.com/en-us/office/opening-csv-utf-8-files-correctly-in-excel-8a935af5-3416-4edd-ba7e-3dfd2bc4a032){.external target="_blank"} for properly opening a UTF-8 file with Excel. You may also consider working with Google Sheets, which is more easily able to open UTF-8 files, or with an open-source tool like Open Office.
:::

For more guidance on how to convert or properly export a file with UTF-8 encoding, check out documentation on sites like [Stack Overflow](https://stackoverflow.com/questions/4221176/excel-to-csv-with-utf8-encoding){.external target="_blank"}. If larger-scale fixes are necessary, [technical options](https://www.kaggle.com/code/alexisbcook/character-encodings){.external target="_blank"} are available.

## Linked Datasets{#linked-datasets}

Does your submission include multiple linked datasets? For instance, ‚Äú[The Index of Major Literary Prizes in the US](https://data.post45.org/posts/the-index-of-major-literary-prizes-in-the-us/){.external target="_blank"}‚Äù includes both a dataset listing the ‚ÄúMajor Literary Prize Winners and Judges‚Äù AND another listing the metadata for the ‚ÄúPrize-Winning Authors‚Äô Books‚Äù‚Äîtwo connected but distinct sets of data. To allow for easy, accessible cross-analysis, please ensure that:

* ‚Ä¶ cross-listed data like author names are **consistent across datasets** (or that intentional variations are explained in your data essay)  
* ‚Ä¶ unique IDs **do not duplicate** across datasets (e.g. same ID for both a line of author data and a line of publication data)

![][styleguide1]

> **Example**: *First two entries for Toni Morrison in ‚Äú[Major Literary Prize Winners and Judges](https://data.post45.org/posts/the-index-of-major-literary-prizes-in-the-us/#data-table){.external target="_blank"}"*

![][styleguide2]

> **Example**: *Entry for Toni Morrison‚Äôs* Beloved *in ‚Äú[Prize-Winning Authors‚Äô Books](https://data.post45.org/posts/the-index-of-major-literary-prizes-in-the-us/#data-table-1){.external target="_blank"},‚Äù a dataset linked to the one above. Though the author and full_name formats differ, the datasets are still easily linked using the LCCN and VIAF ID fields.*

---

# <font color="midnightblue">**Data Structure**</font>{#data-structure}

## Scope{#scope}

To make your data usable for future researchers, we recommend limiting your scope in the following ways:

* Wherever possible, **limit data to one value** (e.g. one date, one name, or one type of description) per cell. Unlike values should not appear together.

  * The decision to include multiple values in a cell is subjective; however, a good rule of thumb is that **if you consider each datapoint to be important on its own, it should have its own cell**.  
  * If you require **multiple entries for the same category**, we generally recommend using additional column headings (e.g. author1, author2, author3) instead of additional values in the same cell. You can see an example in [‚ÄúThe Canon of Asian American Literature.‚Äù](https://data.post45.org/posts/asian-american-literature/#data-table){.external target="_blank"}  
  * Representing **overlapping racial or ethnic identity categories** in data can be challenging. Post45 Data Collective authors have sometimes chosen to represent these overlapping categories in the same cell, and sometimes in different columns or rows. You can see an example of ethnic identity categories [in the same cell](https://data.post45.org/posts/british-literary-prizes/#data-table){.external target="_blank"}, and [in separate rows](https://data.post45.org/posts/british-literary-prizes/#data-table-1){.external target="_blank"} in ‚ÄúSelected British Literary Prizes.‚Äù   
    * The affordance of representing categories in different rows is that it is easier to aggregate and analyze patterns, such as the number of white or Black authors separate from other nationality or ethnicity categories (see [Categories](#categories)).

* **Standardize the *type* of information** included in each field. This is especially important to consider for freeform fields such as ‚Äúnotes‚Äù or ‚Äúdescription‚Äù that rely on a researcher‚Äôs subjective interpretation. Instead of putting every piece of information into one field (e.g. notes), split and categorize the types of information being gathered to make them more legible (e.g. physical\_description, image\_description, advertisements, summary, related\_texts) (see [Other Descriptive Data](#other-descriptive-data)).

![][styleguide3]

> **Example**: *Note how the ‚Äú[Time Horizons of Futuristic Fiction](https://data.post45.org/posts/futuristic-fiction/){.external target="_blank"}‚Äù dataset separates freeform fields like ‚Äúnotes‚Äù and ‚Äúpredictions‚Äù based on the types of information they contain*

## Rows & Columns{#rows-columns}

The columns of your dataset should reflect the categories of data you have collected (e.g. title, author), with each row representing a single entry (e.g. *Beloved*, Toni Morrison). For information on formatting row values, see [Data Types](#data-types). The following represents the **Post45 Data Collective‚Äôs preferred house style:** 

* All column names should be formatted in snake case (with underscores separating words) and lowercase letters ‚Äî (e.g. first\_name)  
* All column names should be specific and unique. For example, instead of ‚Äúid,‚Äù use ‚Äúauthor\_id‚Äù  
* All rows should include a unique identifier (e.g. by pub date and author initials: ‚Äú20010203TP,‚Äù a consecutive string: ‚Äún1‚Äù and ‚Äún2,‚Äù etc.)  
* If referring to a person‚Äôs name, please format as ‚Äúfirst\_name,‚Äù ‚Äúlast\_name,‚Äù and/or ‚Äúfull\_name‚Äù (see [Names, Places, and IDs](#names-places-IDs))  
* Avoid abbreviations if possible, excepting those used in external vocabularies (see [External Vocabularies & Authorities](#external-vocabularies-authorities))


## Missing & Unknown Values{#missing-unknown-values}

Datasets will always contain gaps, whether in missing/unknown information, or in fields non-applicable to a given subject. It‚Äôs important to **delineate between all of these slight variations** to ensure that none of them are conflated with one another.

For instance, you might use the following schema to decide which missing or unknown value format is best for you:

| Example Column | Example Entry | Value Type | Context |
| :---- | :---- | :---- | :---- |
| **birth\_date** | unknown | Unknown Information | An author‚Äôs exact birth date is undocumented |
| **title\_of\_winning\_book** | N/A | Not Applicable to Subject | An author won the award for their career rather than individual book |
| **notes** | NaN\* | Missing Information | No applicable notes included by researcher |

> **‚ÄúNaN‚Äù stands for ‚ÄúNot a Number,‚Äù and can be translated from coding language into ‚Äúthis space intentionally left blank.‚Äù*

Be sure to also check for **outliers and inconsistencies** across data. If a large chunk of data is missing (e.g. a specific date range), ensure that this is not due to a research gap on your end. Whatever the reason for a large data gap, your data essay provides a useful space to provide an explanation (and, if necessary, a reflection on its potential impact on analysis).

## External Vocabularies & Authorities{#external-vocabularies-authorities}

External vocabularies and authorities provide accessible language, curated by experts, that help to **standardize and link data across platforms, datasets, and institutions**. For instance, a Library of Congress name authority for ‚ÄúPrince‚Äù will help users not only to differentiate him from titled royals, but also to ensure that, even when he is listed in three different entries as ‚ÄúPrince,‚Äù ‚ÄúArtist Formerly Known as Prince,‚Äù and ‚ÄúPrince Rogers Nelson,‚Äù these names will all still be linked back to the same person.

::: {.callout-note appearance="default"}
## **Example Vocabularies & Authorities**
* [Library of Congress](https://authorities.loc.gov/webvoy.htm){.external target="_blank"}  Names, Subjects/Keywords 
* [Wikidata](https://www.wikidata.org/){.external target="_blank"} Names, Books, and Media 
* [HathiTrust](https://www.hathitrust.org/member-libraries/resources-for-librarians/data-resources/hathifiles/hathifiles-description/){.external target="_blank"} Books 
* [VIAF](https://viaf.org/en){.external target="_blank"} Names, Geography 
* [Getty](https://www.getty.edu/research/tools/vocabularies/index.html){.external target="_blank"} Art & architecture terms, Artist names, Geography 
* [ORCID](https://orcid.org/){.external target="_blank"}  Researcher names 
* [Traditional Knowledge (TK) Labels](https://localcontexts.org/labels/traditional-knowledge-labels/){.external target="_blank"} Keywords for indigenous cultures
:::

![][styleguide4]{.border} 

> **Example**: *Library of Congress name authority for Prince* 

![][styleguide5]{.border}  

> **Example**: *Wikidata entry for Prince*

When incorporating an external vocabulary entry, make sure to include **BOTH the name or word(s) exactly as written in the database AND the ID provided by the organizing institution** (‚Äún84079379‚Äù in the LoC example above or ‚ÄúQ7542‚Äù for Wikidata). No need to look these up manually: digital tools like our [OpenRefine script](https://github.com/Post45-Data-Collective/openrefine-reconciliation-service){.external target="_blank"} will help to automatically match many vocabularies to their IDs.

::: {.callout-note appearance="default"}
## **Important Note on HathiTrust IDs**
At the Post45 Data Collective, we particularly encourage the inclusion of HathiTrust volume IDs for book-related data. These IDs enable researchers to computationally access full text or ‚Äúbags of words‚Äù (unordered text amenable for large-scale analysis) for books that are available in the HathiTrust Digital Library (see the [HTRC Feature Reader GitHub repository](https://github.com/htrc/htrc-feature-reader){.external target="_blank"} for more information). You can find a volume ID in the URL for a specific title. For example, the specific volume of *Pride and Prejudice* found at [https://babel.hathitrust.org/cgi/pt?id=hvd.32044013656053\&seq=1](https://babel.hathitrust.org/cgi/pt?id=hvd.32044013656053&seq=1){.external target="_blank"} has the volume ID hvd.32044013656053. You can use our [OpenRefine tool](https://github.com/Post45-Data-Collective/openrefine-reconciliation-service){.external target="_blank"} to automatically add HathiTrust volume IDs for relevant records. 

Keep in mind that HathiTrust IDs represent **specific volumes** that have been digitized by specific institutions, rather than **title-level** data. A single title like *Pride and Prejudice* is likely to have multiple IDs referring to different editions or digitizations of the same title. If your dataset includes title-level data rather than volume-level data, you will need to standardize and document how you selected which ID(s) to include. For example, you might include: 

* IDs for ALL matching volumes 
* ID for one matching volume, chosen based on edition or other metric 

For clarity, you may also consider supplementing your volume-level HathiTrust data with unifying title-level data from an organization like [Wikidata](https://www.wikidata.org/){.external target="_blank"}.
:::

---

# <font color="midnightblue">**Data Types**</font>{#data-types}

The following standards for formatting entries in your dataset will ensure that your data is sortable, machine-readable, and easily parsable for human readers. In all cases, column names may be duplicated serially for the purposes of multiple entries (e.g. genre1, genre 2, genre3) (see: [Data Structure](#data-structure)).

**Note**: If your data is intended to be primarily archival, you may opt to prioritize item-level accuracy over standardization (see: [General Tips & Suggestions](#general-tips-suggestions)), or to include multiple versions of the same data. Your choices on this matter should be reflected in your data essay.

## Names, Places, and IDs{#names-places-IDs}

### Personal Names {#personal-names}

**Use one or more of the following**: 

* 2 columns with headings ‚Äúfirst\_name‚Äù and ‚Äúlast\_name‚Äù 
* 1 column with heading ‚Äúfull\_name‚Äù or with descriptor by type (e.g. ‚Äúauthor\_name‚Äù) 
  - Entries can be formatted as either ‚ÄúFirst Name Last Name‚Äù OR ‚ÄúLast name, First name,‚Äù though consistency across entries is encouraged  
* 1 or more columns as defined by external vocabulary, including authority name in heading (e.g. ‚Äúloc\_name,‚Äù ‚Äúwiki\_name‚Äù, ‚ÄúVIAF‚Äù)


| first_name | last_name | author_name | loc_name |
| :---- | :---- | :---- | :---- |
| Ursula K. | Le Guin | Le Guin, Ursula K. | Le Guin, Ursula K. 1929-2018 | 
> **Example**: *The level of granularity you use will vary by use case*  

**In all cases**: 

* Ensure variant spellings and versions are standardized (e.g. either ‚ÄúForster, E.M.‚Äù or ‚ÄúForster, Edward Morgan,‚Äù not both) 
* In the case of names that may have changed over time (e.g. due to marriage, gender transition, etc.), solutions will vary by dataset and potential use cases. However, make sure that you are consistent with your choice and that you document it in your data essay.

### Institutional Names{#institutional-names}

**Use one or more of the following**: 

* 1 column with heading ‚Äúinstitutional\_affiliation‚Äù 
* 1 or more columns with headings by type (e.g. ‚Äúpublisher,‚Äù ‚Äúundergraduate\_inst,‚Äù ‚Äúgranting\_org,‚Äù etc.) 
* 1 or more columns as defined by external vocabulary, including type and authority name in heading (e.g. ‚Äúloc\_publisher,‚Äù ‚Äúviaf\_university,‚Äù etc.) 

**In all cases**: 

* Ensure variant spellings and versions are standardized (e.g. either ‚ÄúEmory‚Äù or ‚ÄúEmory University,‚Äù not both)
* In the case of names that may have changed over time (e.g. ‚ÄúPenguin‚Äù & ‚ÄúRandom House‚Äù vs. ‚ÄúPenguin Random House‚Äù), solutions will vary by dataset and potential use cases. However, make sure that you are consistent with your choice and that you document it in your data essay.

### Geographical Names{#geographical-names}

**Use 1 or more of the following**: 

* 1 column with heading ‚Äúplace‚Äù or with heading by type-variant (e.g. ‚Äúpublisher\_place,‚Äù ‚Äúbirth\_place‚Äù) 
* 2 or more columns with heading by type-level (e.g. ‚Äústate,‚Äù ‚Äúcountry,‚Äù etc.) 
* 1 or more columns as defined by external vocabulary, including type and authority name in heading (e.g. ‚ÄúTGN\_place,‚Äù ‚Äúviaf\_country‚Äù) 

| pub_place | pub_country | pub_state | pub_city |
| :---- | :---- | :---- | :---- |
| Cincinnati, OH | United States | Ohio | Cincinnati | 
> **Example**: *The level of granularity you use will vary by use case. In most instances ‚Äúpub_place‚Äù on its own would be fine.*  

**In all cases**:  

* Ensure variant spellings and versions are standardized (e.g. either ‚ÄúSt. Louis‚Äù or ‚ÄúSaint Louis,‚Äù not both) 
* In the case of names that may have changed over time or that they have variant cultural names (e.g. ‚ÄúOkmulgee, OK‚Äù or ‚ÄúMuscogee Creek Nation‚Äù), solutions will vary by dataset and potential use cases. However, make sure that you are consistent with your choice and that you document it in your data essay.

### Unique IDs{#unique-IDs}

Include IDs for ALL external vocabulary or authority terms used in your dataset (see [Data Structure](#data-structure)). 

**In all cases**: 

* Use headings that include type and authority name, and ID indicator (e.g. ‚Äúviaf_name_url,‚Äù ‚Äútk_family_id‚Äù) 
* EITHER use the ID on its own or the URL version of the ID (e.g. ‚Äún84079379‚Äù or ‚Äúhttps://lccn.loc.gov/n84079379.‚Äù Be consistent. 

|loc_name | loc_name_id | TGN_place | TGN_place_url | 
| :---- | :---- | :---- | :---- |
Le Guin, Ursula K., 1929-2018 | n78095474 | Cincinnati (inhabited place) | http://vocab.getty.edu/page/tgn/2007971 |
> **Example**: *Library of Congress & Getty identifiers*

## Numbers{#numbers}

### Dates{#dates}

**Headings** 

* Headings will vary by dataset scope and use case. We recommend indicating ‚Äútype‚Äù of date in the heading, especially if more than one date column is present in the dataset (e.g. ‚Äúpub_date,‚Äù ‚Äúbirth_date‚Äù) 

**Entries** 

* Use [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601){.external target="_blank"} format for ALL featured dates (e.g. ‚Äú1794-07-27‚Äù) 
* If only one section of the ISO date is relevant (e.g. publication year), you may shorten to that relevant section; however, always maintain the basic order of yyyy-mm-dd 
* You may also include human-readable, ‚Äúas-described on text‚Äù date information in a separate entry (e.g. ‚ÄúJuly 27, ‚Äò94‚Äù). However this information should be supplemental to the ISO entry and should be labeled appropriately (e.g. ‚Äúdate\_on\_text‚Äù) 

| pub_date | date_on_issue |
| :---- | :---- |
| 1976-10-03 | Oct. 3, 1976 |
| 1976 | 3 Oct. 1976 |
> **Example**: *two versions of date data. The first (ISO) is required;  the second is optional.*

**Approximations** 

* ISO and [Library of Congress](https://www.loc.gov/standards/datetime/){.external target="_blank"} guidelines suggest the following formats for approximate dates: 
  - To refer to a decade, indicate only the first 3 digits for the year entry, followed by an x for the remaining digit (e.g. ‚Äú201x‚Äù for 2010-2019) 
  - To refer to a century, indicate only the first 2 digits for the year entry, followed by x‚Äôs for the remaining digits (e.g. ‚Äú18xx‚Äù for 1800-1899) 
  - To indicate that a listed date is uncertain, append with a question mark (e.g. ‚Äú1603-10-12?‚Äù) 
  - To indicate a listed date is approximate, append with a tilde (e.g. ‚Äú1794-07-27\~‚Äù) 

For additional variations, including information on formatting intervals, durations, and times, check out this helpful [blog post](https://www.datafix.com.au/BASHing/2020-02-12.html){.external target="_blank"} from *BASHing data*.

### Integers{#integers}

**Headings** 

* We recommend indicating the ‚Äútype‚Äù of integer in the heading (e.g. ‚Äúno\_award,‚Äù for number of awards or ‚Äúbl\_id‚Äù for IDs registered by the British Library) 

**Entries** 

* If integers begin or end with zeros, programs like Excel will often automatically erase the zeroes upon import. To prevent this, we recommend surrounding the integer with single or double quotation marks to ensure the field is interpreted as ‚Äútext‚Äù rather than ‚Äúnumber.‚Äù We also recommend that you use functions in programs like [OpenRefine](https://forum.openrefine.org/t/add-final-punctuation/671){.external target="_blank"} or [Excel](https://learn.microsoft.com/en-us/answers/questions/5026707/excel-how-to-put-a-single-quote-\(-\)-in-front-of-ea){.external target="_blank"} to automate this process, rather than adding punctuation manually. 

| Original Entry | Excel Import - with quotation marks | Excel Import - without quotation marks|
| :---- | :---- | :---- |
|000609702 | ‚Äú000609702‚Äù | 609702 |
> **Example**: *this is what import errors for integers might look like*

**Approximations**

* To indicate an unknown digit within an integer, use an x for that digit (e.g. ‚Äú12x‚Äù for ‚Äúone-hundred-twenty-something‚Äù) 
* To indicate that an integer is uncertain, append with a question mark (e.g. ‚Äú5,004,236?‚Äù) 
* To indicate an integer is approximate, append with a tilde (e.g. ‚Äú23\~‚Äù)


## Publication Data{#publication-data}

### Contributors{#contributers}

If the publications in your dataset include multiple types of contribution (e.g. edited collections as well as monographs), consider a standardized way to document contributors. 

**Use 1 or more of the following to identify multiple types and numbers of contributors**: 

* If you want to keep a single name column, title it ‚Äúcontributor‚Äù or ‚Äúcreator‚Äù rather than ‚Äúauthor‚Äù 
  - Categorize type of role in a separate column (e.g. creator: ‚ÄúLahiri, Jhumpa,‚Äù role: ‚Äúeditor‚Äù) 
* To delineate within the column titles themselves, include multiple name columns, such as ‚Äúprimary\_contributor‚Äù and ‚Äúother\_contributors‚Äù or ‚Äúauthor‚Äù and ‚Äúeditor‚Äù

### Editions{#editions}

Depending on the scope and use cases of your dataset, it may be useful to include edition data about publications. For instance, if a future researcher wanted to analyze the impact of male editors on books written by women in the 19th century, they would require metadata indicating both the 1818 and 1831 editions of *Frankenstein* are included in the dataset. 

**Use 1 or more of the following to identify edition data**: 

* A column with heading ‚Äúedition‚Äù and entries consistently formatted (e.g. ‚Äú1st ed,‚Äù ‚Äúfirst edition,‚Äù or ‚Äú1818 edition,‚Äù not all 3)
* ISBN/ISSN, if period-applicable (see below)

### Serials / Series{#serials-series}

**Serialized texts may benefit from using 1 or more of these additional fields**: 

* A ‚Äúserial‚Äù title column in addition to the main title entry to account for titles of special issues, title changes across time, episodes of a series, etc.  
* 1 or more fields for unit release information (e.g. ‚Äúvolume,‚Äù ‚Äúnumber,‚Äù ‚Äúseason\_no,‚Äù ‚Äúepisode\_no‚Äù) 
  - Though publications themselves may use multiple formats for this information (e.g. ‚Äúvol. II‚Äù followed by ‚Äúvol. 3‚Äù), standardize your own formatting as much as possible 
* 1 or more ‚Äúcontributors‚Äù columns and/or 1  or more ‚Äúeditor‚Äù columns (see above) 
* If academic journal, include a column for DOI 

| ep_title | series_title | season_no | episode_no|
| :---- | :---- | :---- |:---- |
Amok Time | Star Trek: The Original Series | ‚Äú2‚Äù | ‚Äú1‚Äù |
> **Example**: *entries for a serial publication*

### ISBN/ISSN{#isbn-issn}

Including the ISBN or ISSN for a publication can make specific bibliographic information more accessible. Tools like our [OpenRefine script](https://github.com/Post45-Data-Collective/openrefine-reconciliation-service){.external target="_blank"} or citation managers like [Zotero](https://www.zotero.org/){.external target="_blank"} can easily automate searches for this information. 

::: {.callout-note appearance="default"}
## **Quick Note** 
When importing this data from other sources, extraneous information is often included to indicate edition information (e.g. ‚Äú0670030074 (alk. paper)‚Äù). For sorting purposes, we recommend trimming this to just the number.
:::

### Pagination{#pagination}

More often than not, you will be importing pagination data from a secondary source rather than formatting it from scratch. However, if you are paginating archival materials manually, be sure to use consistent formatting (e.g. ‚Äú5 pages‚Äù or ‚Äú5 p.,‚Äù not both). 

If you are concerned about variations and exceptions (a particular problem in historical texts or esoteric genres), [library cataloging sources](https://manual.stcv.be/p/Pagination,_Foliation_and_Columns){.external target="_blank"} may provide some guidance.

### Language{#language}

When describing the language(s) used in a publication, use [ISO 639-2](https://www.loc.gov/standards/iso639-2/php/code_list.php){.external target="_blank"} codes. 

You may also include human-readable terms to describe a text‚Äôs language in a separate entry (e.g. ‚ÄúTagalog‚Äù in addition to ‚Äútgl‚Äù). However this information should be supplemental to the ISO entry and should be labeled appropriately (e.g. ‚Äúlanguage‚Äù vs. ‚Äúlanguage\_code‚Äù)

| language | language_code |
| :---- | :---- | 
| Igbo | ibo |
| French | fre | 
> **Example**: *two versions of language data. The first (ISO) is required;  the second is optional.*

### Copyright{#copyright}

Depending on the scope and type of data in your dataset, it may be helpful to include copyright information for each text.

* You can find statements to use (and accompanying URIs) [here](https://rightsstatements.org/page/1.0/?language=en){.external target="_blank"}.
* If the item is in the Creative Commons, you can use the statements and URIs listed [here](https://creativecommons.org/chooser/){.external target="_blank"}.
* If you need to locate the copyright status of a book, NYPL maintains an ‚Äúunofficial‚Äù *Catalog of Copyright Entries* search interface [here](https://cce-search.nypl.org/about){.external target="_blank"}. 

| title | rights_type | rights_statement | rights_URI |
| :---- | :---- | :---- | :---- |
| How to Write an Autobiographical Novel | IN COPYRIGHT | ‚ÄúThis Item is protected by copyright and/or related rights. You are free to use this Item in any way that is permitted by the copyright and related rights legislation that applies to your use. For other uses you need to obtain permission from the rights-holder(s).‚Äù | http://rightsstatements.org/vocab/InC/1.0/ | 
| ‚ÄúLicence to build: Public attitudes to public sector AI‚Äù | CC BY 4.0 | ‚ÄúThis license enables reusers to distribute, remix, adapt, and build upon the material in any medium or format, so long as attribution is given to the creator. The license allows for commercial use. CC BY includes the following elements: BY: credit must be given to the creator.‚Äù | https://creativecommons.org/licenses/by/4.0/ |

> **Example**: *two variations of copyright documentation*

## Subjects & Keywords{#subjects-keywords}

If you are using subject headings or keywords to describe your data, it will likely be useful to use external vocabularies that have already been standardized and linked across databases (see [External Vocabularies & Authorities](#external-vocabularies-authorities)).

If you choose to generate your own keywords, ensure that you stay consistent throughout (e.g. ‚ÄúLGBT fiction‚Äù or ‚Äúqueer fiction,‚Äù not both, unless you‚Äôre specifically analyzing the difference between the designations). 

In both cases, we recommend using keywords only for entry-specific cases. For instance, if every entry in a dataset represents a novel, there is no need to include ‚Äúnovels‚Äù as a keyword in every single entry.


## Categories{#categories}

Categorizing your data can bring with it a host of ethical questions. How you decide to navigate these questions will vary based on the type of data you‚Äôre working with‚Äîif you are categorizing an author‚Äôs race, that is likely to be thornier than determining a novel‚Äôs genre. Either way, there will always be gaps, problems, and imperfections in our categorization. Be sure to document your decision-making process carefully in your data essay, and account for the inevitable gaps and simplifications in your results there.

Here are a few suggestions for thinking through your categorization schemes in your data itself:

* **Navigating Taxonomies**

  * Pick a schema based on the objectives of your project and stick to it. If you are categorizing films by genre to analyze genre‚Äôs impact on box office success, for instance, consider using industry standard vocabulary rather than more academic terms (e.g. ‚Äúscience fiction‚Äù rather than ‚Äúspeculative fiction‚Äù); if you are categorizing films by genre to document changes in genre conventions over time, you might expand into sub-categories (e.g. ‚Äúperiod film‚Äù and ‚Äúhistorical epic‚Äù for one film, and ‚Äúperiod film‚Äù and ‚Äúbiopic‚Äù for another).

    * If your audience is in a particular discipline or community, you might prioritize using categories that will be familiar to them (e.g. [Classics of Science Fiction](https://csfquery.com/){.external target="_blank"} database, [Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/){.external target="_blank"}).

  * If your data ascribes identity categories to real people, be thoughtful about your process for determining them. When the person is real (not a fictional character), self-identification should be top priority. Beyond that, your methods will inevitably be imperfect: a person‚Äôs race or gender can‚Äôt be assumed from photos or names, [whiteness](https://journals.sagepub.com/doi/10.1177/1464700107078139){.external target="_blank"} is treated as a default and rarely named explicitly, and [journalistic coverage](https://bloodlettermag.com/enough-rope-transmasculine-erasure-violence-and-reading-trans-horror/){.external target="_blank"} can‚Äôt always be trusted for accuracy. If your objective is to [draw attention to inequality](https://www.theatlantic.com/books/archive/2024/06/diversity-publishing-backlash-study/678734/){.external target="_blank"}, this categorization is nevertheless important work. Research thoroughly, be critical of your methods as you go, and acknowledge their imperfections in writing, rather than attempting to claim objectivity.

    * For example, in *Redlining Culture* (2020), Richard Jean So uses the following approach: ‚Äútwo researchers had to independently find a scholarly source, or an instance of author self-identification, that marked that author as a specific gender and/or racial category, and the researchers had to agree in their findings. If this standard could not be reached, the author was left unmarked‚Äù (p. 194, n. 53).

  * When describing or categorizing works by marginalized groups, try as much as possible to use vocabularies responsible to and governed by those groups. [Traditional Knowledge Labels](https://localcontexts.org/labels/traditional-knowledge-labels/){.external target="_blank"}, for instance, prioritize community-generated and identified language, rather than relying on potentially [harmful colonial language](https://dr.lib.iastate.edu/entities/publication/17f01738-7738-4c2c-be86-ea7fd870d115){.external target="_blank"} to describe indigenous communities.

    
## Other Descriptive Data{#other-descriptive-data}

Depending on the scope and type of data in your dataset, you may require some fields that are less standardizable than the ones described above. Describing the physical condition or paratextual details of an object, for instance, will require some amount of subjective, descriptive language.

**We recommend the following guidelines for fields like these**:

* Rather than relegating all of this descriptive information to a single ‚Äúnotes‚Äù entry, divide them out as much as possible into separate fields. For instance ‚Äúphysical\_desc‚Äù should be separate from ‚Äúdata\_source‚Äù should be separate from ‚Äúresearcher\_notes‚Äù should be separate from ‚Äúadd\_info‚Äù from an external source. This will make information more searchable and less overwhelming to read.

* Even when you‚Äôre not listing specific, standardized categories or vocabularies, try to use descriptive, consistent keywords that will help others find your data. Ensure those keywords are sufficient and representative for the subject at hand.

*Original Version*

| item_id | physical_desc |
| :---- | :---- |
| book001  | hinges loose, 225-232 different page color, back flyleaf has doodles. some wear on covers |
| book002 | some pages are loose and brittle, some discoloration throughout, cover and title page are shattering. Book is held in an enclosure and the final page has interesting marginalia. Some pages are stiff and do not open past \~130 degrees. |

*Revised Version* 

| item_id | physical_desc |
| :---- | :---- |
| book001 | Damaged copy - pages loose, covers worn; Variant coloration (pp. 225-232); Marginalia - drawings (back flyleaf) |
| book002 | Damaged copy - pages loose and brittle, spine stiff (throughout); Discoloration (throughout); Marginalia - notes (p. 131); Preservation - archival enclosure  |

> **Example**: *note how the revised version is shorter and easier to read due to its use of standardized language*

---

# <font color="midnightblue">**Acknowledgements**</font>

This data style guide draws language, information, and inspiration from the [C19 Data Collective Data Documentation guide](https://c19datacollective.com/criteria/data-documentation/){.external target="_blank"} and [Humanities Data Preparation Guide](https://doi.org/10.17605/OSF.IO/C9N5K){.external target="_blank"}, as well as the [Digital Curation Network](https://datacuration.network/){.external target="_blank"}. Enormous thanks in particular to Sarah E. Reiff Conell, Research Data Management Specialist at Princeton University Library, for her gracious guidance, support, and permissions.

Thank you to the following parties for their generous feedback on this document: Karl Berglund, Julie Enszer, Long Le-Khac, Jordan Pruett, Lindsay Thomas, Ted Underwood, and Grant Wythoff.

	

[styleguide1]: /images/styleguide1.png
[styleguide2]: /images/styleguide2.png
[styleguide3]: /images/styleguide3.png
[styleguide4]: /images/styleguide4.png
[styleguide5]: /images/styleguide5.png